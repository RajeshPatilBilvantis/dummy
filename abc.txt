"""
Validation script for LightGBM next‑product model.

Goal:
- Take a random sample of ~5,000 multi‑policy clients (clients with 2+ policies),
  use ONLY their first‑policy features as model input, and compare the model's
  predicted next product to the ACTUAL second product.

Notes on methodology
--------------------
- This is a good way to *validate the model + preprocessing logic end‑to‑end*,
  because it mirrors the training setup:
    - Input features: first policy + client/asset features
    - Target: second product category
- It complements the train/val/test split already done in
  `Data extraction and model training.ipynb` by:
    - Re‑using the same preprocessing logic from `final_preprocessor.py`
    - Loading the registered MLflow model
    - Producing a labeled validation table you can inspect in SQL/BI tools

Implementation details
----------------------
- We re‑use `preprocess_for_training` from `final_preprocessor.py` to:
    - Filter to clients with 2+ policies
    - Build first/second policy pairs
    - Engineer all features exactly as in training (including
      years_to_second_policy = second - first)
- We then:
    - Concatenate train/val/test splits into a single pool
    - Sample 5,000 rows at random
    - Run predictions using the registered LightGBM model
    - Map integer labels back to product categories via `id2prod`
    - Save a Spark table with: cont_id, true product, predicted product, etc.
"""

import mlflow
import mlflow.lightgbm
import numpy as np
import pandas as pd

from pyspark.sql import SparkSession
from pyspark.sql import functions as F

from final_preprocessor import preprocess_for_training


# ============================================================================
# CONFIGURATION
# ============================================================================

CATALOG_NAME = "eda_smartlist"
SCHEMA_NAME = "models"
MODEL_NAME = "lgbm_model_hyperparameter_310126"
MODEL_VERSION = "1"

MODEL_URI = f"models:/{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}/{MODEL_VERSION}"

TABLE_NAME = "dl_tenants_daas.us_wealth_management.wealth_management_client_metrics"

# Optional filters (align with production if needed)
BRANCHOFFICE_CODE = "83"  # or None
BUSINESS_MONTH = None     # set to an int (e.g., 202501) to restrict by month, or keep None

# Validation sampling
VALIDATION_SAMPLE_SIZE = 5000
RANDOM_SEED = 42

# Output table for detailed comparison
VALIDATION_OUTPUT_TABLE = (
    "eda_smartlist.us_wealth_management_smartlist."
    "ML_validation_multi_policy_first_to_second"
)


print("=" * 80)
print("Starting Validation: First Policy → Second Product")
print("=" * 80)

spark = SparkSession.builder.getOrCreate()

# ----------------------------------------------------------------------
# 1. Load raw data (same source as training / final_pipeline)
# ----------------------------------------------------------------------
print("\nLoading raw data from Unity Catalog table...")
df_raw = spark.table(TABLE_NAME)

if BRANCHOFFICE_CODE:
    df_raw = df_raw.filter(F.col("branchoffice_code") == BRANCHOFFICE_CODE)
    print(f"  ✓ Filtered by branchoffice_code = {BRANCHOFFICE_CODE}")

if BUSINESS_MONTH:
    df_raw = df_raw.filter(F.col("business_month") == BUSINESS_MONTH)
    print(f"  ✓ Filtered by business_month = {BUSINESS_MONTH}")

# Keep only Active policies to match training
df_raw = df_raw.filter(F.col("policy_status") == "Active")
print(f"  ✓ Filtered to Active policies only")
print(f"  Rows after filtering: {df_raw.count():,}")

# ----------------------------------------------------------------------
# 2. Preprocess for training (2+ policy clients, first→second mapping)
# ----------------------------------------------------------------------
print("\nPreprocessing data for training-style first→second mapping...")

(
    train_pd,
    val_pd,
    test_pd,
    feature_cols,
    prod2id,
    id2prod,
    label_map,
    categorical_mappings,
    num_classes,
) = preprocess_for_training(
    spark=spark,
    df_raw=df_raw,
    sample_fraction=None,  # use full filtered data
    random_seed=RANDOM_SEED,
)

print("  ✓ Preprocessing complete")
print(f"    Train shape: {train_pd.shape}")
print(f"    Val shape:   {val_pd.shape}")
print(f"    Test shape:  {test_pd.shape}")
print(f"    Num classes: {num_classes}")

# Combine all splits into a single pool of labeled examples
full_pd = pd.concat([train_pd, val_pd, test_pd], ignore_index=True)
print(f"    Combined pool size: {len(full_pd):,} rows")

# ----------------------------------------------------------------------
# 3. Sample ~5,000 validation records
# ----------------------------------------------------------------------
n_total = len(full_pd)
n_sample = min(VALIDATION_SAMPLE_SIZE, n_total)

print(f"\nSampling {n_sample:,} validation rows (from {n_total:,})...")
sample_pd = full_pd.sample(
    n=n_sample, random_state=RANDOM_SEED, replace=False
).reset_index(drop=True)

# ----------------------------------------------------------------------
# 4. Load registered LightGBM model from MLflow
# ----------------------------------------------------------------------
print("\nLoading registered LightGBM model from MLflow...")
model = mlflow.lightgbm.load_model(MODEL_URI)
print(f"  ✓ Model loaded from {MODEL_URI}")

# ----------------------------------------------------------------------
# 5. Run predictions using ONLY first‑policy feature set
# ----------------------------------------------------------------------
print("\nRunning predictions on validation sample...")

X_val = sample_pd[feature_cols]
y_true_ids = sample_pd["label"].values

y_pred_proba = model.predict(X_val)
y_pred_ids = np.argmax(y_pred_proba, axis=1)

# Map label IDs back to product categories
y_true_prod = [id2prod.get(int(lbl), "UNKNOWN") for lbl in y_true_ids]
y_pred_prod = [id2prod.get(int(lbl), "UNKNOWN") for lbl in y_pred_ids]

# ----------------------------------------------------------------------
# 6. Build validation result DataFrame
# ----------------------------------------------------------------------
print("\nBuilding validation comparison DataFrame...")

result_pd = pd.DataFrame(
    {
        "cont_id": sample_pd["cont_id"],
        "true_label_id": y_true_ids,
        "true_product_category": y_true_prod,
        "pred_label_id": y_pred_ids,
        "pred_product_category": y_pred_prod,
    }
)

# Attach a few key first‑policy features for context (optional)
context_cols = [
    "first_acct_val_amt",
    "first_face_amt",
    "first_cash_val_amt",
    "wc_total_assets",
    "psn_age",
    "age_at_first_policy",
    "years_to_second_policy",
]
for col in context_cols:
    if col in sample_pd.columns:
        result_pd[col] = sample_pd[col]

# Basic accuracy metrics
accuracy = (result_pd["true_label_id"] == result_pd["pred_label_id"]).mean()
print(f"\nValidation Accuracy on sampled {n_sample:,} rows: {accuracy:.4f}")

display(result_pd)
