# ============================================
# SHAP ANALYSIS FOR PREDICTIONS + AGENT TALKING POINTS
# ============================================

import shap
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

print("=" * 60)
print("SHAP ANALYSIS FOR CLIENT PREDICTIONS")
print("=" * 60)

# Use prediction data for SHAP analysis (sample if too large)
shap_sample_size = min(100, len(pred_pd))
shap_pred_data = pred_pd[feature_cols_final].iloc[:shap_sample_size].copy()
shap_pred_indices = pred_pd.iloc[:shap_sample_size].index

# Get corresponding final_predictions data for demographic info
if len(final_predictions) >= shap_sample_size:
    shap_final_preds = final_predictions.iloc[:shap_sample_size].copy()
else:
    shap_final_preds = final_predictions.copy()

print(f"\nComputing SHAP values for {len(shap_pred_data)} prediction samples...")
print(f"Number of features: {len(feature_cols_final)}")

# Create SHAP explainer
explainer = shap.TreeExplainer(model)

# Calculate SHAP values for predictions
shap_values_pred = explainer.shap_values(shap_pred_data)

# Handle different SHAP output formats
if isinstance(shap_values_pred, list):
    # List of arrays (one per class)
    num_classes = len(shap_values_pred)
    print(f"SHAP values format: List of {num_classes} arrays")
    print(f"Each array shape: {shap_values_pred[0].shape}")
else:
    # Single array - convert to list format
    shap_array = np.array(shap_values_pred)
    if len(shap_array.shape) == 3:
        # Shape is (n_samples, n_features, n_classes) - need to transpose
        num_classes = shap_array.shape[2]
        shap_values_pred = [shap_array[:, :, i] for i in range(num_classes)]
        print(f"SHAP values format: Array shape {shap_array.shape}, converted to list of {num_classes} arrays")
    else:
        num_classes = 1
        shap_values_pred = [shap_array]
        print(f"SHAP values format: Single array shape {shap_array.shape}")

print(f"Number of classes: {num_classes}")

# ------------- 1) Overall Feature Importance -------------
print("\n" + "=" * 60)
print("OVERALL FEATURE IMPORTANCE")
print("=" * 60)

feature_importance_pred = {}
for i, feat in enumerate(feature_cols_final):
    # Calculate mean absolute SHAP value across all classes
    importance = np.mean([np.mean(np.abs(sv[:, i])) for sv in shap_values_pred])
    feature_importance_pred[feat] = importance

feature_importance_sorted = sorted(feature_importance_pred.items(), key=lambda x: x[1], reverse=True)
shap_importance_df = pd.DataFrame(feature_importance_sorted, columns=['Feature', 'Mean_|SHAP_Value|'])
shap_importance_df['Rank'] = range(1, len(shap_importance_df) + 1)

print("\nTop 15 Most Important Features for Predictions:")
display(shap_importance_df.head(15))

# ------------- 2) Generate Talking Points for Each Client -------------
print("\n" + "=" * 60)
print("GENERATING AGENT TALKING POINTS")
print("=" * 60)

# Get product name mapping - handle case where label_map might not be available
try:
    # Try to use label_map if available (from training)
    inv_label_map = {v: k for k, v in label_map.items()}
    final_id2prod = {model_id: id2prod[original_id] for model_id, original_id in inv_label_map.items()}
except NameError:
    # If label_map not available, use id2prod directly (assuming it's available from cell 4 or cell 12)
    try:
        # Use id2prod directly - the pred_class_id should map directly to product names
        final_id2prod = id2prod.copy()
    except NameError:
        # If id2prod also not available, create default mapping
        print("Warning: id2prod not found. Using default product mapping.")
        final_id2prod = {0: "DISABILITY", 1: "HEALTH", 2: "INVESTMENT", 3: "LIFE_INSURANCE", 
                         4: "NETWORK_PRODUCTS", 5: "OTHER", 6: "RETIREMENT"}

# Create talking points DataFrame
talking_points_list = []

for idx in range(len(shap_pred_data)):
    actual_idx = shap_pred_indices[idx]
    client_id = pred_pd.iloc[actual_idx]['cont_id']
    pred_class = pred_pd.iloc[actual_idx]['pred_class_id']
    pred_product = pred_pd.iloc[actual_idx]['pred_product']
    pred_prob = pred_pd.iloc[actual_idx]['pred_prob']
    
    # Get demographic data if available
    client_demo = None
    if idx < len(shap_final_preds):
        client_demo = shap_final_preds.iloc[idx]
    
    # Get SHAP values for the predicted class
    # Ensure pred_class is within valid range
    if pred_class >= len(shap_values_pred):
        pred_class = len(shap_values_pred) - 1
    shap_vals = shap_values_pred[pred_class][idx]
    
    # Get top contributing features (positive and negative)
    feature_contributions = []
    for i, feat in enumerate(feature_cols_final):
        contrib = shap_vals[i]
        feature_contributions.append({
            'feature': feat,
            'shap_value': contrib,
            'feature_value': shap_pred_data.iloc[idx][feat]
        })
    
    # Sort by absolute SHAP value
    feature_contributions.sort(key=lambda x: abs(x['shap_value']), reverse=True)
    
    # Get top 5 positive and top 3 negative contributors
    top_positive = [f for f in feature_contributions if f['shap_value'] > 0][:5]
    top_negative = [f for f in feature_contributions if f['shap_value'] < 0][:3]
    
    # Build talking points
    talking_points = []
    
    # Main recommendation
    talking_points.append(f"Based on your client profile and purchase history, we recommend {pred_product} with {pred_prob*100:.1f}% confidence.")
    
    # Positive drivers
    if top_positive:
        talking_points.append("\nKey reasons for this recommendation:")
        for i, contrib in enumerate(top_positive, 1):
            feat = contrib['feature']
            val = contrib['feature_value']
            shap_val = contrib['shap_value']
            
            # Interpret feature values - updated for new feature set from cell 4
            if feat == 'first_product_category_idx':
                # Try to get actual product category name
                try:
                    if client_demo is not None and 'product_category' in client_demo:
                        product_cat = client_demo['product_category']
                        talking_points.append(f"  {i}. Your current product ({product_cat}) indicates strong alignment with {pred_product}.")
                    else:
                        talking_points.append(f"  {i}. Your current product profile strongly supports {pred_product}.")
                except:
                    talking_points.append(f"  {i}. Your product profile strongly supports {pred_product}.")
            
            elif feat.startswith('first_') and ('acct_val' in feat or 'face_amt' in feat or 'cash_val' in feat):
                # First policy financial features
                if 'acct_val' in feat:
                    talking_points.append(f"  {i}. Your account value of ${val:,.0f} indicates strong capacity for {pred_product}.")
                elif 'face_amt' in feat:
                    talking_points.append(f"  {i}. Your face amount of ${val:,.0f} shows significant coverage, supporting {pred_product}.")
                elif 'cash_val' in feat:
                    if val > 0:
                        talking_points.append(f"  {i}. Your cash value of ${val:,.0f} demonstrates accumulated value, aligning with {pred_product}.")
                    else:
                        talking_points.append(f"  {i}. Your financial profile indicates {pred_product} would be an excellent fit.")
            
            elif 'allocation_ratio' in feat:
                # Asset allocation ratios
                ratio_type = feat.replace('_allocation_ratio', '').replace('stock', 'stocks').replace('bond', 'bonds')
                if val > 0:
                    talking_points.append(f"  {i}. Your {ratio_type} allocation ({val:.1%}) indicates a portfolio structure that supports {pred_product}.")
                else:
                    talking_points.append(f"  {i}. Your asset allocation profile suggests {pred_product} would complement your portfolio.")
            
            elif feat == 'age_at_first_policy':
                age_val = int(val) if val > 0 else None
                if age_val:
                    talking_points.append(f"  {i}. At age {age_val} when you first purchased, {pred_product} aligns well with your life stage and financial planning needs.")
                else:
                    talking_points.append(f"  {i}. Your age profile indicates {pred_product} would be an excellent fit for your financial goals.")
            
            elif feat == 'years_to_second_policy':
                # For single-policy clients, this will be 0, so we can skip or provide generic message
                if val > 0:
                    talking_points.append(f"  {i}. Your engagement pattern over {val:.1f} years shows readiness for {pred_product}.")
                # Skip if 0 (single policy clients)
            
            elif feat == 'psn_age':
                age_val = int(val) if val > 0 else (int(client_demo['psn_age']) if client_demo is not None and 'psn_age' in client_demo and pd.notna(client_demo['psn_age']) else None)
                if age_val:
                    talking_points.append(f"  {i}. At age {age_val}, {pred_product} aligns well with your life stage and financial planning needs.")
                else:
                    talking_points.append(f"  {i}. Your age profile indicates {pred_product} would be an excellent fit for your financial goals.")
            
            elif feat == 'client_tenure' or 'tenure' in feat.lower():
                tenure_val = val if val > 0 else (client_demo['client_tenure'] if client_demo is not None and 'client_tenure' in client_demo and pd.notna(client_demo['client_tenure']) else None)
                if tenure_val:
                    talking_points.append(f"  {i}. With {tenure_val:.1f} years as our client, {pred_product} represents a natural next step in your relationship with us.")
                else:
                    talking_points.append(f"  {i}. As a valued client, {pred_product} represents a natural next step in your relationship with us.")
            
            elif feat == 'wc_total_assets':
                if val > 0:
                    talking_points.append(f"  {i}. Your total assets of ${val:,.0f} indicate strong capacity for {pred_product}.")
                else:
                    talking_points.append(f"  {i}. Your asset profile indicates {pred_product} would be an excellent fit for your portfolio.")
            
            elif feat.startswith('wc_assetmix_'):
                asset_type = feat.replace('wc_assetmix_', '').replace('_', ' ')
                if val > 0:
                    talking_points.append(f"  {i}. Your {asset_type} allocation of ${val:,.0f} shows a portfolio structure that supports {pred_product}.")
                else:
                    talking_points.append(f"  {i}. Your asset mix profile suggests {pred_product} would complement your portfolio.")
            
            elif 'aum' in feat.lower() or 'asset' in feat.lower():
                talking_points.append(f"  {i}. Your asset profile indicates {pred_product} would be an excellent fit for your portfolio.")
            
            elif 'channel' in feat.lower():
                talking_points.append(f"  {i}. Clients in your channel typically benefit from {pred_product}.")
            
            elif 'season' in feat.lower():
                season_map = {'Q1': 'Q1 (Jan-Mar)', 'Q2': 'Q2 (Apr-Jun)', 'Q3': 'Q3 (Jul-Sep)', 'Q4': 'Q4 (Oct-Dec)'}
                season_name = season_map.get(str(val), str(val))
                talking_points.append(f"  {i}. Your policy timing ({season_name}) indicates a strategic approach that aligns with {pred_product}.")
            
            elif feat.endswith('_idx'):
                # Skip index features in talking points (they're not meaningful to clients)
                continue
            
            else:
                talking_points.append(f"  {i}. Your {feat.replace('_', ' ')} profile strongly supports {pred_product}.")
    
    # Address potential concerns (negative contributors)
    if top_negative:
        talking_points.append("\nConsiderations:")
        for contrib in top_negative:
            feat = contrib['feature']
            # Only mention if it's a significant concern
            if abs(contrib['shap_value']) > 0.1:
                if 'age' in feat.lower():
                    talking_points.append(f"  - While age is a factor, {pred_product} still offers significant value for your situation.")
                elif 'allocation' in feat.lower() or 'asset' in feat.lower():
                    talking_points.append(f"  - Your current asset allocation is considered, and {pred_product} still presents a strong opportunity.")
                elif feat.endswith('_idx'):
                    # Skip index features in considerations
                    continue
                else:
                    talking_points.append(f"  - While {feat.replace('_', ' ')} is a consideration, {pred_product} still offers significant value for your situation.")
    
    # Add call to action
    talking_points.append(f"\nNext Steps: Let's schedule a consultation to discuss how {pred_product} can help you achieve your financial goals.")
    
    talking_points_list.append({
        'cont_id': client_id,
        'predicted_product': pred_product,
        'confidence': f"{pred_prob*100:.1f}%",
        'talking_points': '\n'.join(talking_points),
        'top_positive_features': ', '.join([f['feature'] for f in top_positive[:3]]),
        'top_negative_features': ', '.join([f['feature'] for f in top_negative[:2]])
    })

# Create talking points DataFrame
talking_points_df = pd.DataFrame(talking_points_list)

print(f"\nGenerated talking points for {len(talking_points_df)} clients")
print("\nSample talking points for first client:")
print("-" * 60)
print(talking_points_df.iloc[0]['talking_points'])
print("-" * 60)

# ------------- 3) Summary Statistics by Predicted Product -------------
print("\n" + "=" * 60)
print("PREDICTION SUMMARY BY PRODUCT")
print("=" * 60)

pred_summary = final_predictions.groupby('pred_product').agg({
    'cont_id': 'count',
    'pred_prob': ['mean', 'min', 'max']
}).round(3)
pred_summary.columns = ['Count', 'Avg_Confidence', 'Min_Confidence', 'Max_Confidence']
pred_summary = pred_summary.sort_values('Count', ascending=False)
print("\nPredictions by Product:")
display(pred_summary)

# ------------- 4) Feature Importance by Predicted Product -------------
print("\n" + "=" * 60)
print("FEATURE IMPORTANCE BY PREDICTED PRODUCT")
print("=" * 60)

for product in final_predictions['pred_product'].unique():
    product_mask = pred_pd['pred_product'] == product
    if product_mask.sum() > 0:
        # Get indices in pred_pd for this product
        product_pred_indices = pred_pd[product_mask].index[:min(50, product_mask.sum())]
        
        # Map to shap_pred_data indices (only include those in our SHAP sample)
        shap_pred_indices_list = shap_pred_indices.tolist() if hasattr(shap_pred_indices, 'tolist') else list(shap_pred_indices)
        product_shap_indices = []
        for pred_idx in product_pred_indices:
            try:
                shap_idx = shap_pred_indices_list.index(pred_idx)
                product_shap_indices.append(shap_idx)
            except ValueError:
                continue  # Skip if not in SHAP sample
        
        if len(product_shap_indices) > 0:
            # Get SHAP values for this product's predicted class
            product_pred_class = pred_pd.iloc[product_pred_indices[0]]['pred_class_id']
            # Ensure product_pred_class is within valid range
            if product_pred_class >= len(shap_values_pred):
                product_pred_class = len(shap_values_pred) - 1
            
            product_shap_vals = shap_values_pred[product_pred_class][product_shap_indices]
            
            # Calculate feature importance for this product
            product_feat_importance = {}
            for i, feat in enumerate(feature_cols_final):
                product_feat_importance[feat] = np.mean(np.abs(product_shap_vals[:, i]))
            
            product_feat_sorted = sorted(product_feat_importance.items(), key=lambda x: x[1], reverse=True)
            product_feat_df = pd.DataFrame(product_feat_sorted[:10], columns=['Feature', 'Importance'])
            
            print(f"\nTop 10 Features for {product} predictions:")
            display(product_feat_df)

# ------------- 5) Create Final Output with Talking Points -------------
print("\n" + "=" * 60)
print("FINAL OUTPUT: PREDICTIONS WITH TALKING POINTS")
print("=" * 60)

# Merge talking points with final predictions
final_with_talking_points = final_predictions.merge(
    talking_points_df[['cont_id', 'talking_points', 'top_positive_features', 'top_negative_features']],
    left_on='cont_id',
    right_on='cont_id',
    how='left'
)

# Reorder columns
output_cols = [
    'cont_id', 'axa_party_id', 'predicted_product', 'pred_product', 'pred_prob',
    'confidence', 'talking_points', 'top_positive_features', 'top_negative_features',
    'product_category', 'psn_age', 'client_seg', 'aum_band', 'channel', 
    'division_name', 'branch_name', 'business_city', 'business_state_cod', 'client_tenure'
] + [c for c in final_with_talking_points.columns if c.startswith('prob_')]

# Select available columns
available_cols = [c for c in output_cols if c in final_with_talking_points.columns]
final_with_talking_points = final_with_talking_points[available_cols]

# Rename for clarity
final_with_talking_points = final_with_talking_points.rename(columns={
    'pred_product': 'recommended_product',
    'pred_prob': 'recommendation_confidence'
})

print(f"\nFinal output shape: {final_with_talking_points.shape}")
print("\nSample output (first 3 rows):")
display(final_with_talking_points.head(3))

# Save to variable for easy access
agent_pitch_data = final_with_talking_points.copy()

# ------------- 6) Create Agent Summary Report -------------
print("\n" + "=" * 60)
print("AGENT SUMMARY REPORT")
print("=" * 60)

# Summary by product
product_summary = agent_pitch_data.groupby('recommended_product').agg({
    'cont_id': 'count',
    'recommendation_confidence': ['mean', 'min', 'max']
}).round(3)
product_summary.columns = ['Client_Count', 'Avg_Confidence', 'Min_Confidence', 'Max_Confidence']
product_summary = product_summary.sort_values('Client_Count', ascending=False)

print("\nðŸ“Š Recommendations Summary by Product:")
display(product_summary)

# High confidence recommendations (>70%)
high_confidence = agent_pitch_data[agent_pitch_data['recommendation_confidence'] > 0.7]
print(f"\nðŸŽ¯ High Confidence Recommendations (>70%): {len(high_confidence)} clients")
if len(high_confidence) > 0:
    print("\nTop 5 High Confidence Clients:")
    high_conf_display = high_confidence[['cont_id', 'recommended_product', 'recommendation_confidence']].head(5)
    display(high_conf_display)

# Recommendations by client segment
if 'client_seg' in agent_pitch_data.columns:
    seg_summary = agent_pitch_data.groupby(['client_seg', 'recommended_product']).size().reset_index(name='count')
    seg_summary = seg_summary.sort_values('count', ascending=False)
    print("\nðŸ‘¥ Recommendations by Client Segment:")
    display(seg_summary.head(10))

# Recommendations by age group
if 'psn_age' in agent_pitch_data.columns:
    agent_pitch_data['age_group'] = pd.cut(
        agent_pitch_data['psn_age'], 
        bins=[0, 35, 50, 65, 100], 
        labels=['<35', '35-50', '50-65', '65+']
    )
    age_summary = agent_pitch_data.groupby(['age_group', 'recommended_product']).size().reset_index(name='count')
    age_summary = age_summary.sort_values('count', ascending=False)
    print("\nðŸ‘¤ Recommendations by Age Group:")
    display(age_summary)

print("\n" + "=" * 60)
print("ANALYSIS COMPLETE!")
print("=" * 60)
print(f"\nâœ… Use 'agent_pitch_data' DataFrame to access predictions with talking points.")
print(f"ðŸ“‹ Total clients with recommendations: {len(agent_pitch_data)}")
print(f"ðŸ“¦ Products recommended: {agent_pitch_data['recommended_product'].nunique()}")
print(f"ðŸ“ˆ Average confidence: {agent_pitch_data['recommendation_confidence'].mean()*100:.1f}%")
print(f"\nðŸ’¡ Each row in 'agent_pitch_data' contains:")
print("   - Client information (cont_id, demographics)")
print("   - Recommended product and confidence score")
print("   - Personalized talking points based on SHAP analysis")
print("   - Top contributing features for the recommendation")
