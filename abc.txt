# Check what columns are available in df_encoded
print(f"\n  Columns in df_encoded: {len(df_encoded.columns)}")
print(f"  Sample columns: {df_encoded.columns[:10]}...")

# Convert to pandas
select_cols = ["cont_id", "axa_party_id"] + feature_cols
# Filter to only columns that actually exist in df_encoded
available_cols = [col for col in select_cols if col in df_encoded.columns]
missing_cols = [col for col in select_cols if col not in df_encoded.columns]

if missing_cols:
    print(f"\n⚠ Missing columns in df_encoded: {missing_cols}")
    print(f"  This might be expected if columns were renamed or not created during preprocessing")

features_pd = df_encoded.select(available_cols).toPandas()
features_pd.fillna(0, inplace=True)

print(f"\n✓ Reconstructed features for {len(features_pd):,} clients")
print(f"✓ Feature columns available: {len([c for c in feature_cols if c in features_pd.columns])}/{len(feature_cols)}")
if len([c for c in feature_cols if c not in features_pd.columns]) > 0:
    missing = [c for c in feature_cols if c not in features_pd.columns]
    print(f"⚠ Missing feature columns in final output: {missing}")
    print(f"  These will be excluded from SHAP analysis")


==================================


# ============================================================================
# MERGE PREDICTIONS WITH FEATURES
# ============================================================================

# Check which feature columns are available in features_pd
available_feature_cols = [col for col in feature_cols if col in features_pd.columns]
missing_feature_cols = [col for col in feature_cols if col not in features_pd.columns]

if missing_feature_cols:
    print(f"⚠ Warning: Missing feature columns in reconstructed data: {missing_feature_cols}")
    print(f"  Available: {len(available_feature_cols)}/{len(feature_cols)} feature columns")
    # Use only available columns
    feature_cols_to_use = available_feature_cols
else:
    feature_cols_to_use = feature_cols

print(f"✓ Using {len(feature_cols_to_use)} feature columns for SHAP analysis")

# Merge predictions with features
pred_with_features = pred_pd.merge(
    features_pd[["cont_id"] + feature_cols_to_use], on="cont_id", how="inner"
)

print(f"✓ Merged predictions with features: {len(pred_with_features):,} records")

# Ensure we have feature data for all predictions
if len(pred_with_features) < len(pred_pd):
    missing = len(pred_pd) - len(pred_with_features)
    print(f"⚠ Warning: {missing} predictions missing feature data (will be skipped)")

# Verify all required columns are present
missing_in_merged = [col for col in feature_cols_to_use if col not in pred_with_features.columns]
if missing_in_merged:
    print(f"⚠ Warning: Columns missing after merge: {missing_in_merged}")
    # Remove missing columns from feature_cols_to_use
    feature_cols_to_use = [col for col in feature_cols_to_use if col in pred_with_features.columns]
    print(f"  Updated to {len(feature_cols_to_use)} available feature columns")


=============================


# ============================================================================
# SHAP ANALYSIS FOR REASONING
# ============================================================================

print("\n" + "=" * 80)
print("COMPUTING SHAP VALUES FOR REASONING")
print("=" * 80)

# Verify all feature columns are present before proceeding
missing_cols = [col for col in feature_cols_to_use if col not in pred_with_features.columns]
if missing_cols:
    raise ValueError(f"Missing required feature columns: {missing_cols}\n"
                   f"Available columns: {list(pred_with_features.columns)}")

# Prepare feature matrix using only available columns
X = pred_with_features[feature_cols_to_use].values

print(f"✓ Feature matrix shape: {X.shape}")

# Compute SHAP values
print("Computing SHAP values (this may take a while)...")
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X)

# Get predictions to determine which class SHAP values to use
pred_probs = model.predict(X)
pred_class_ids = np.argmax(pred_probs, axis=1)

# Handle SHAP output format
if isinstance(shap_values, list):
    # List of arrays: one array per class
    shap_array = np.array([shap_values[pred_class_ids[i]][i] for i in range(len(pred_with_features))])
elif isinstance(shap_values, np.ndarray) and len(shap_values.shape) == 3:
    # 3D array: (n_samples, n_features, n_classes) or (n_classes, n_samples, n_features)
    n_samples, n_features, n_classes = shap_values.shape
    if n_samples == len(pred_with_features) and n_features == len(feature_cols_to_use):
        shap_array = np.array([shap_values[i, :, pred_class_ids[i]] for i in range(n_samples)])
    else:
        shap_values = shap_values.transpose(1, 0, 2)  # Try transpose
        shap_array = np.array([shap_values[i, :, pred_class_ids[i]] for i in range(len(pred_with_features))])
else:
    shap_array = shap_values

print(f"✓ Computed SHAP values: {shap_array.shape}")

# Also compute SHAP values for all classes (for comparative analysis)
if isinstance(shap_values, list):
    shap_all_classes = shap_values  # Already in list format
elif isinstance(shap_values, np.ndarray) and len(shap_values.shape) == 3:
    # Convert to list format for easier access
    if shap_values.shape[0] == len(pred_with_features):
        shap_all_classes = [shap_values[:, :, i] for i in range(shap_values.shape[2])]
    else:
        shap_all_classes = [shap_values[i, :, :].T for i in range(shap_values.shape[0])]
else:
    shap_all_classes = [shap_array]  # Single class

# Update feature_cols to match what we actually used
feature_cols = feature_cols_to_use

print(f"✓ SHAP analysis complete")
