0:	learn: 0.6047631	test: 0.4744231	best: 0.4744231 (0)	total: 1.09s	remaining: 54m 36s
100:	learn: 0.7054510	test: 0.5710659	best: 0.5710659 (100)	total: 1m 31s	remaining: 43m 35s
200:	learn: 0.7328467	test: 0.5941824	best: 0.5941824 (200)	total: 3m 6s	remaining: 43m 17s
300:	learn: 0.7447581	test: 0.6036515	best: 0.6038589 (299)	total: 4m 37s	remaining: 41m 30s
400:	learn: 0.7522608	test: 0.6093795	best: 0.6093795 (400)	total: 6m 7s	remaining: 39m 40s
500:	learn: 0.7571735	test: 0.6127425	best: 0.6128008 (499)	total: 7m 37s	remaining: 38m 3s
600:	learn: 0.7611473	test: 0.6154677	best: 0.6155626 (593)	total: 9m 7s	remaining: 36m 26s
700:	learn: 0.7646058	test: 0.6178110	best: 0.6179799 (697)	total: 10m 35s	remaining: 34m 44s
800:	learn: 0.7676921	test: 0.6198935	best: 0.6198935 (800)	total: 11m 59s	remaining: 32m 56s
900:	learn: 0.7701771	test: 0.6219979	best: 0.6220838 (899)	total: 13m 25s	remaining: 31m 16s
1000:	learn: 0.7725376	test: 0.6242071	best: 0.6243065 (995)	total: 14m 50s	remaining: 29m 37s
1100:	learn: 0.7744480	test: 0.6259263	best: 0.6260174 (1094)	total: 16m 15s	remaining: 28m 2s
1200:	learn: 0.7763710	test: 0.6276192	best: 0.6276192 (1200)	total: 17m 42s	remaining: 26m 31s
1300:	learn: 0.7782515	test: 0.6290440	best: 0.6291871 (1296)	total: 19m 8s	remaining: 25m
1400:	learn: 0.7799321	test: 0.6300406	best: 0.6300406 (1400)	total: 20m 35s	remaining: 23m 29s
1500:	learn: 0.7813156	test: 0.6310325	best: 0.6310325 (1500)	total: 22m 2s	remaining: 22m
1600:	learn: 0.7825933	test: 0.6324460	best: 0.6324460 (1600)	total: 23m 29s	remaining: 20m 31s
1700:	learn: 0.7841226	test: 0.6337033	best: 0.6337033 (1700)	total: 24m 56s	remaining: 19m 2s
1800:	learn: 0.7853159	test: 0.6348146	best: 0.6348707 (1795)	total: 26m 23s	remaining: 17m 34s
1900:	learn: 0.7864678	test: 0.6352832	best: 0.6353368 (1879)	total: 27m 51s	remaining: 16m 6s
2000:	learn: 0.7874774	test: 0.6361066	best: 0.6361639 (1988)	total: 29m 18s	remaining: 14m 37s
2100:	learn: 0.7885793	test: 0.6375110	best: 0.6375110 (2100)	total: 30m 46s	remaining: 13m 10s
2200:	learn: 0.7895174	test: 0.6380583	best: 0.6381184 (2196)	total: 32m 12s	remaining: 11m 41s
2300:	learn: 0.7906076	test: 0.6386896	best: 0.6387447 (2299)	total: 33m 39s	remaining: 10m 13s
2400:	learn: 0.7915048	test: 0.6393133	best: 0.6394050 (2399)	total: 35m 7s	remaining: 8m 45s
2500:	learn: 0.7923522	test: 0.6399486	best: 0.6399781 (2496)	total: 36m 33s	remaining: 7m 17s
2600:	learn: 0.7932254	test: 0.6404825	best: 0.6404825 (2600)	total: 37m 59s	remaining: 5m 49s
2700:	learn: 0.7941267	test: 0.6413758	best: 0.6413758 (2700)	total: 39m 27s	remaining: 4m 22s
2800:	learn: 0.7949896	test: 0.6419066	best: 0.6419231 (2796)	total: 40m 58s	remaining: 2m 54s
2900:	learn: 0.7956822	test: 0.6422704	best: 0.6422704 (2900)	total: 42m 29s	remaining: 1m 27s
2999:	learn: 0.7964658	test: 0.6423524	best: 0.6424803 (2968)	total: 43m 59s	remaining: 0us

bestTest = 0.642480294
bestIteration = 2968

Shrink model to first 2969 iterations.
Regularized CatBoost model trained

=== Model Performance ===
Macro F1: 0.5237
Weighted F1: 0.6917
Accuracy: 0.6941
Macro Precision: 0.5562
Macro Recall: 0.5138

=== Classification Report ===
                  precision    recall  f1-score   support

      INVESTMENT       0.68      0.81      0.74     39542
  LIFE_INSURANCE       0.73      0.72      0.72     33278
NETWORK_PRODUCTS       0.30      0.27      0.29      8004
    OTHER_HEALTH       0.31      0.12      0.17       181
      RETIREMENT       0.76      0.65      0.70     44287

        accuracy                           0.69    125292
       macro avg       0.56      0.51      0.52    125292
    weighted avg       0.70      0.69      0.69    125292


=== Top 20 Feature Importances ===
                          feature  importance
23                years_to_second   16.322938
30        days_since_first_policy    9.761881
36                  register_year    7.342270
45   agent_most_common_cross_sell    6.203703
8             sub_product_level_2    4.288838
52      years_product_interaction    3.959699
9                   division_name    3.736597
48        product_age_interaction    3.636867
3                         psn_age    3.500351
40      agent_p1_cross_sell_count    3.258629
49  product_agent_seg_interaction    3.165730
22            age_at_first_policy    2.875596
41     branch_p1_cross_sell_count    2.507805
7             sub_product_level_1    2.430216
46               agent_avg_assets    2.172167
47        product_aum_interaction    2.120610
5                    client_seg_1    2.015161
26                   log_face_amt    1.816990
27               log_cash_val_amt    1.520008
33                 register_month    1.495218

=== Per-Class Performance Analysis ===

Confusion Matrix:
                  INVESTMENT  LIFE_INSURANCE  ...  OTHER_HEALTH  RETIREMENT
INVESTMENT             32163            2230  ...             0        3822
LIFE_INSURANCE          4173           23806  ...            40        3459
NETWORK_PRODUCTS        2337            1765  ...             0        1706
OTHER_HEALTH               9             138  ...            21          10
RETIREMENT              8771            4676  ...             6       28785

[5 rows x 5 columns]

=== Prediction Distribution ===
                  True Count  Predicted Count  Difference  Difference %
INVESTMENT             39542            47453        7911         20.01
LIFE_INSURANCE         33278            32615        -663         -1.99
NETWORK_PRODUCTS        8004             7375        -629         -7.86
OTHER_HEALTH             181               67        -114        -62.98
RETIREMENT             44287            37782       -6505        -14.69



=== Applying Per-Class Threshold Tuning ===
RETIREMENT: optimal threshold = 0.300, F1 = 0.715
INVESTMENT: optimal threshold = 0.300, F1 = 0.746
LIFE_INSURANCE: optimal threshold = 0.330, F1 = 0.728
NETWORK_PRODUCTS: optimal threshold = 0.290, F1 = 0.311
OTHER_HEALTH: optimal threshold = 0.200, F1 = 0.273

=== Threshold Tuning Results ===
Original Macro F1: 0.5237
Tuned Macro F1: 0.5236
Improvement: -0.0001

Original Weighted F1: 0.6917
Tuned Weighted F1: 0.6916
Improvement: -0.0001

=== Updated Classification Report (After Threshold Tuning) ===
                  precision    recall  f1-score   support

      INVESTMENT       0.68      0.81      0.74     39542
  LIFE_INSURANCE       0.73      0.71      0.72     33278
NETWORK_PRODUCTS       0.30      0.28      0.29      8004
    OTHER_HEALTH       0.31      0.12      0.17       181
      RETIREMENT       0.76      0.65      0.70     44287

        accuracy                           0.69    125292
       macro avg       0.56      0.51      0.52    125292
    weighted avg       0.70      0.69      0.69    125292


WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: dbstoragezkstig75rk7f4.blob.core.windows.net. Connection pool size: 10

Individual Model Performance:
  CatBoost Macro F1: 0.5236
  XGBoost Macro F1: 0.4975
  LightGBM Macro F1: 0.4846

=== Creating Ensemble Predictions ===
RETIREMENT: optimal threshold = 0.410, F1 = 0.614
INVESTMENT: optimal threshold = 0.400, F1 = 0.626
LIFE_INSURANCE: optimal threshold = 0.260, F1 = 0.722
NETWORK_PRODUCTS: optimal threshold = 0.190, F1 = 0.310
OTHER_HEALTH: optimal threshold = 0.400, F1 = 0.113

=== Final Ensemble Performance (with threshold tuning) ===
Ensemble Macro F1: 0.5023
Ensemble Weighted F1: 0.6585
Single CatBoost Macro F1: 0.5236
Improvement: -0.0213

=== Final Classification Report (Ensemble + Threshold Tuning) ===
                  precision    recall  f1-score   support

      INVESTMENT       0.70      0.64      0.67     39542
  LIFE_INSURANCE       0.71      0.74      0.72     33278
NETWORK_PRODUCTS       0.27      0.27      0.27      8004
    OTHER_HEALTH       0.26      0.13      0.18       181
      RETIREMENT       0.66      0.69      0.67     44287

        accuracy                           0.66    125292
       macro avg       0.52      0.49      0.50    125292
    weighted avg       0.66      0.66      0.66    125292
