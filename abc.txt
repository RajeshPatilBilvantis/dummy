How to use:::

Run Cells 1‚Äì5 (data loading and preprocessing)
Run Cell 6 (enhanced training)
See results immediately
Optional:
Run Cell 7 for hyperparameter tuning (then re-run Cell 5)
Run Cell 8 for ensemble method






[I 2025-12-30 11:06:00,521] A new study created in memory with name: lgbm_optimization
============================================================
HYPERPARAMETER TUNING WITH OPTUNA
============================================================
‚ö†Ô∏è  This will take 10-30 minutes depending on data size...
   You can stop early with Ctrl+C if needed.

[W 2025-12-30 11:06:15,643] Trial 0 failed with parameters: {'learning_rate': 0.016934292828768748, 'num_leaves': 125, 'min_data_in_leaf': 92, 'feature_fraction': 0.9186851505220401, 'subsample': 0.9279495264279036, 'lambda_l1': 0.9908006931673967, 'lambda_l2': 3.966408265043625e-06, 'max_depth': 8, 'min_gain_to_split': 0.45725000533275684, 'max_bin': 250} because of the following error: ValueError('The entry associated with the validation name "valid_0" and the metric name "val-multi_logloss" is not found in the evaluation result list [(\'val\', \'multi_logloss\', 1.4570868957345915, False)].').
Traceback (most recent call last):
  File "/databricks/python/lib/python3.12/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/root/.ipykernel/1778/command-7985721800795380-1136038742", line 62, in objective
    model_tune = lgb.train(
                 ^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 483, in safe_patch_function
    patch_function(call_original, *args, **kwargs)
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 182, in patch_with_managed_run
    result = patch_function(original, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/lightgbm/__init__.py", line 883, in train
    return train_impl(_log_models, _log_datasets, original, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/lightgbm/__init__.py", line 796, in train_impl
    model = original(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 474, in call_original
    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 425, in call_original_fn_with_event_logging
    original_fn_result = original_fn(*og_args, **og_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 471, in _original_fn
    original_result = original(*_og_args, **_og_kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/lightgbm/engine.py", line 317, in train
    cb(
  File "/databricks/python/lib/python3.12/site-packages/optuna_integration/lightgbm.py", line 138, in __call__
    raise ValueError(
ValueError: The entry associated with the validation name "valid_0" and the metric name "val-multi_logloss" is not found in the evaluation result list [('val', 'multi_logloss', 1.4570868957345915, False)].
[W 2025-12-30 11:06:15,645] Trial 0 failed with value None.









# ============================================
# STEP 20: HYPERPARAMETER TUNING WITH OPTUNA (OPTIONAL)
# ============================================
#
# This cell is OPTIONAL but recommended for best performance.
# It will tune hyperparameters and update LGB_PARAMS_TUNED.
# After running this, re-run Cell 5 to train with tuned parameters.
#
# ============================================

# Install optuna if needed
# %pip install optuna

try:
    import optuna
    from optuna.integration import LightGBMPruningCallback
    OPTUNA_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Optuna not available. Install with: %pip install optuna")
    print("   Skipping hyperparameter tuning...")
    OPTUNA_AVAILABLE = False

if OPTUNA_AVAILABLE:
    print("="*60)
    print("HYPERPARAMETER TUNING WITH OPTUNA")
    print("="*60)
    print("‚ö†Ô∏è  This will take 10-30 minutes depending on data size...")
    print("   You can stop early with Ctrl+C if needed.\n")
    
    def objective(trial):
        """Optuna objective function for hyperparameter tuning"""
        
        # Suggest hyperparameters
        params = {
            "objective": "multiclass",
            "num_class": num_classes,
            "metric": "multi_logloss",
            "boosting_type": "gbdt",
            "verbosity": -1,
            "force_row_wise": True,
            
            # Tune these parameters
            "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.1, log=True),
            "num_leaves": trial.suggest_int("num_leaves", 64, 256),
            "min_data_in_leaf": trial.suggest_int("min_data_in_leaf", 20, 100),
            "feature_fraction": trial.suggest_float("feature_fraction", 0.7, 0.95),
            "subsample": trial.suggest_float("subsample", 0.7, 0.95),
            "lambda_l1": trial.suggest_float("lambda_l1", 1e-8, 10.0, log=True),
            "lambda_l2": trial.suggest_float("lambda_l2", 1e-8, 10.0, log=True),
            "max_depth": trial.suggest_int("max_depth", 8, 15),
            "min_gain_to_split": trial.suggest_float("min_gain_to_split", 0.0, 1.0),
            "max_bin": trial.suggest_int("max_bin", 200, 300),
        }
        
        # Create datasets
        train_ds_tune = lgb.Dataset(train_pd[feature_cols_final], label=train_pd["label0"])
        val_ds_tune = lgb.Dataset(val_pd[feature_cols_final], label=val_pd["label0"], reference=train_ds_tune)
        
        # Train model
        pruning_callback = LightGBMPruningCallback(trial, "val-multi_logloss")
        
        model_tune = lgb.train(
            params,
            train_ds_tune,
            valid_sets=[val_ds_tune],
            valid_names=["val"],
            num_boost_round=500,  # Fewer rounds for tuning
            callbacks=[pruning_callback, lgb.early_stopping(30)]
        )
        
        # Evaluate
        val_pred_prob = model_tune.predict(val_pd[feature_cols_final])
        val_pred = np.argmax(val_pred_prob, axis=1)
        f1 = f1_score(val_pd["label0"], val_pred, average="weighted")
        
        return f1
    
    # Run optimization
    study = optuna.create_study(direction="maximize", study_name="lgbm_optimization")
    study.optimize(objective, n_trials=20, timeout=3600)  # 20 trials or 1 hour
    
    print("\n" + "="*60)
    print("OPTIMIZATION RESULTS")
    print("="*60)
    print(f"üéØ Best F1-weighted score: {study.best_value:.4f}")
    print("\nüìã Best parameters found:")
    for key, value in study.best_params.items():
        print(f"  {key}: {value}")
    
    # Update LGB_PARAMS_TUNED with best parameters
    LGB_PARAMS_TUNED = LGB_PARAMS_ENHANCED.copy()
    LGB_PARAMS_TUNED.update(study.best_params)
    LGB_PARAMS_TUNED["objective"] = "multiclass"
    LGB_PARAMS_TUNED["num_class"] = num_classes
    LGB_PARAMS_TUNED["metric"] = "multi_logloss"
    LGB_PARAMS_TUNED["verbosity"] = -1
    LGB_PARAMS_TUNED["force_row_wise"] = True
    
    print("\n‚úÖ Tuned parameters saved to LGB_PARAMS_TUNED")
    print("üí° Now re-run Cell 5 to train model with tuned parameters!")
else:
    print("\n‚ö†Ô∏è  Skipping hyperparameter tuning (Optuna not available)")
    print("   Using enhanced parameters from Cell 5")
    # LGB_PARAMS_TUNED already set in Cell 5



========================================================================================
==========================================================================================


# ============================================
# STEP 20: HYPERPARAMETER TUNING WITH OPTUNA (OPTIONAL)
# ============================================
#
# This cell is OPTIONAL but recommended for best performance.
# It will tune hyperparameters and update LGB_PARAMS_TUNED.
# After running this, re-run Cell 5 to train with tuned parameters.
#
# ============================================

# Install optuna if needed
# %pip install optuna

try:
    import optuna
    from optuna.integration import LightGBMPruningCallback
    OPTUNA_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  Optuna not available. Install with: %pip install optuna")
    print("   Skipping hyperparameter tuning...")
    OPTUNA_AVAILABLE = False

if OPTUNA_AVAILABLE:
    print("="*60)
    print("HYPERPARAMETER TUNING WITH OPTUNA")
    print("="*60)
    print("‚ö†Ô∏è  This will take 10-30 minutes depending on data size...")
    print("   You can stop early with Ctrl+C if needed.\n")
    
    def objective(trial):
        """Optuna objective function for hyperparameter tuning"""
        
        # Suggest hyperparameters
        params = {
            "objective": "multiclass",
            "num_class": num_classes,
            "metric": "multi_logloss",
            "boosting_type": "gbdt",
            "verbosity": -1,
            "force_row_wise": True,
            
            # Tune these parameters
            "learning_rate": trial.suggest_float("learning_rate", 0.01, 0.1, log=True),
            "num_leaves": trial.suggest_int("num_leaves", 64, 256),
            "min_data_in_leaf": trial.suggest_int("min_data_in_leaf", 20, 100),
            "feature_fraction": trial.suggest_float("feature_fraction", 0.7, 0.95),
            "subsample": trial.suggest_float("subsample", 0.7, 0.95),
            "lambda_l1": trial.suggest_float("lambda_l1", 1e-8, 10.0, log=True),
            "lambda_l2": trial.suggest_float("lambda_l2", 1e-8, 10.0, log=True),
            "max_depth": trial.suggest_int("max_depth", 8, 15),
            "min_gain_to_split": trial.suggest_float("min_gain_to_split", 0.0, 1.0),
            "max_bin": trial.suggest_int("max_bin", 200, 300),
        }
        
        # Create datasets
        train_ds_tune = lgb.Dataset(train_pd[feature_cols_final], label=train_pd["label0"])
        val_ds_tune = lgb.Dataset(val_pd[feature_cols_final], label=val_pd["label0"], reference=train_ds_tune)
        
        # Train model
        pruning_callback = LightGBMPruningCallback(trial, "val", "multi_logloss")
        
        model_tune = lgb.train(
            params,
            train_ds_tune,
            valid_sets=[val_ds_tune],
            valid_names=["val"],
            num_boost_round=500,  # Fewer rounds for tuning
            callbacks=[pruning_callback, lgb.early_stopping(30)]
        )
        
        # Evaluate
        val_pred_prob = model_tune.predict(val_pd[feature_cols_final])
        val_pred = np.argmax(val_pred_prob, axis=1)
        f1 = f1_score(val_pd["label0"], val_pred, average="weighted")
        
        return f1
    
    # Run optimization
    study = optuna.create_study(direction="maximize", study_name="lgbm_optimization")
    study.optimize(objective, n_trials=20, timeout=3600)  # 20 trials or 1 hour
    
    print("\n" + "="*60)
    print("OPTIMIZATION RESULTS")
    print("="*60)
    print(f"üéØ Best F1-weighted score: {study.best_value:.4f}")
    print("\nüìã Best parameters found:")
    for key, value in study.best_params.items():
        print(f"  {key}: {value}")
    
    # Update LGB_PARAMS_TUNED with best parameters
    LGB_PARAMS_TUNED = LGB_PARAMS_ENHANCED.copy()
    LGB_PARAMS_TUNED.update(study.best_params)
    LGB_PARAMS_TUNED["objective"] = "multiclass"
    LGB_PARAMS_TUNED["num_class"] = num_classes
    LGB_PARAMS_TUNED["metric"] = "multi_logloss"
    LGB_PARAMS_TUNED["verbosity"] = -1
    LGB_PARAMS_TUNED["force_row_wise"] = True
    
    print("\n‚úÖ Tuned parameters saved to LGB_PARAMS_TUNED")
    print("üí° Now re-run Cell 5 to train model with tuned parameters!")
else:
    print("\n‚ö†Ô∏è  Skipping hyperparameter tuning (Optuna not available)")
    print("   Using enhanced parameters from Cell 5")
    # LGB_PARAMS_TUNED already set in Cell 5





[I 2025-12-30 12:07:02,182] A new study created in memory with name: lgbm_optimization
============================================================
HYPERPARAMETER TUNING WITH OPTUNA
============================================================
‚ö†Ô∏è  This will take 10-30 minutes depending on data size...
   You can stop early with Ctrl+C if needed.

[W 2025-12-30 12:07:16,500] Trial 0 failed with parameters: {'learning_rate': 0.06887290135247841, 'num_leaves': 148, 'min_data_in_leaf': 68, 'feature_fraction': 0.7412133957357806, 'subsample': 0.8461233153106296, 'lambda_l1': 0.1151771521124076, 'lambda_l2': 1.962415857891891e-08, 'max_depth': 14, 'min_gain_to_split': 0.020503631125684763, 'max_bin': 264} because of the following error: ValueError('The intermediate values are inconsistent with the objective valuesin terms of study directions. Please specify a metric to bemaximized for LightGBMPruningCallback.').
Traceback (most recent call last):
  File "/databricks/python/lib/python3.12/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/root/.ipykernel/1778/command-7985721800795380-818757185", line 62, in objective
    model_tune = lgb.train(
                 ^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 483, in safe_patch_function
    patch_function(call_original, *args, **kwargs)
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 182, in patch_with_managed_run
    result = patch_function(original, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/lightgbm/__init__.py", line 883, in train
    return train_impl(_log_models, _log_datasets, original, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/lightgbm/__init__.py", line 796, in train_impl
    model = original(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 474, in call_original
    return call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 425, in call_original_fn_with_event_logging
    original_fn_result = original_fn(*og_args, **og_kwargs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/utils/autologging_utils/safety.py", line 471, in _original_fn
    original_result = original(*_og_args, **_og_kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/lightgbm/engine.py", line 317, in train
    cb(
  File "/databricks/python/lib/python3.12/site-packages/optuna_integration/lightgbm.py", line 156, in __call__
    raise ValueError(
ValueError: The intermediate values are inconsistent with the objective valuesin terms of study directions. Please specify a metric to bemaximized for LightGBMPruningCallback.
[W 2025-12-30 12:07:16,501] Trial 0 failed with value None.
