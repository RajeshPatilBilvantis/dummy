# ============================================================================
# Register PreprocessAndPredictModel in Unity Catalog
# ============================================================================
# This cell registers the model after you've saved your artifacts from training

import mlflow
import mlflow.pyfunc
from mlflow.models.signature import infer_signature
from pyspark.sql import SparkSession
import pandas as pd
import os
import tempfile
import pickle
import sys

# Add path for preprocessing
sys.path.append('/Workspace/Users/rajesh.patil@equitable.com/Final_model_files')

# Import save/load functions if available, otherwise define them
try:
    from preprocess_and_predict import save_model_artifacts, load_model_artifacts
except ImportError:
    # Define the functions if not available
    import lightgbm as lgb
    
def save_model_artifacts(artifacts_dict, path):
    os.makedirs(path, exist_ok=True)
    if 'model' in artifacts_dict:
        model = artifacts_dict.pop('model')
        model.save_model(os.path.join(path, 'model.txt'))
    with open(os.path.join(path, 'artifacts.pkl'), 'wb') as f:
        pickle.dump(artifacts_dict, f)
    print(f"Model artifacts saved to {path}")

def load_model_artifacts(path):
    artifacts = {}
    artifacts_path = os.path.join(path, 'artifacts.pkl')
    if os.path.exists(artifacts_path):
        with open(artifacts_path, 'rb') as f:
            other_artifacts = pickle.load(f)
            artifacts.update(other_artifacts)
    return artifacts

# ============================================================================
# CONFIGURATION
# ============================================================================

# Model registration details
CATALOG_NAME = "eda_smartlist"  # Your Unity Catalog name
SCHEMA_NAME = "models"  # Schema name in Unity Catalog
MODEL_NAME = "preprocess_and_predict_model_lgbm"  # Model name

# # Paths (adjust based on your setup)
ARTIFACTS_PATH = "/Workspace/Users/rajesh.patil@equitable.com/Final_model_files"

# ============================================================================
# STEP 1: Save Model Artifacts (if not already saved)
# ============================================================================

print("=" * 80)
print("STEP 1: Saving/Loading Model Artifacts")
print("=" * 80)

# Load artifacts
try:
    artifacts = load_model_artifacts(ARTIFACTS_PATH)
    print(f"✓ Loaded artifacts from {ARTIFACTS_PATH}")
except Exception as e:
    print(f"✗ Could not load artifacts from {ARTIFACTS_PATH}")
    print(f"  Error: {e}")
    print("  Please ensure artifacts are saved first using save_model_artifacts()")
    raise

# ============================================================================
# STEP 2: Create Sample Input for Signature Inference
# ============================================================================

print("\n" + "=" * 80)
print("STEP 2: Creating Sample Input")
print("=" * 80)

spark = SparkSession.builder.getOrCreate()

# Create sample input - dict with parameters (will load from table)
sample_input = {
    "table_name": "dl_tenants_daas.us_wealth_management.wealth_management_client_metrics",
    "branchoffice_code": "83",
    "business_month": 202511
}

print(f"✓ Created sample input")

# ============================================================================
# STEP 3: Initialize Model and Get Sample Output
# ============================================================================

print("\n" + "=" * 80)
print("STEP 3: Testing Model")
print("=" * 80)

# Create model instance
model_instance = PreprocessAndPredictModel()

# Set artifacts manually (since we're not loading from MLflow context yet)
model_instance.model = "eda_smartlist.models.final_lgbm_multiclass_model"
model_instance.prod2id = artifacts['prod2id']
model_instance.id2prod = artifacts['id2prod']
model_instance.label_map = artifacts['label_map']
model_instance.num_classes = artifacts['num_classes']
model_instance.categorical_mappings = artifacts.get('categorical_mappings')
model_instance.feature_cols = artifacts['feature_cols']
model_instance.max_seq_len = artifacts.get('max_seq_len', 10)

# Test prediction
try:
    sample_output = model_instance.predict(None, sample_input)
    print(f"✓ Model prediction successful")
    print(f"  Output shape: {sample_output.shape}")
    print(f"  Output columns: {list(sample_output.columns)}")
except Exception as e:
    print(f"✗ Model prediction failed")
    print(f"  Error: {e}")
    import traceback
    traceback.print_exc()
    raise
    
# ============================================================================
# STEP 5: Log and Register Model
# ============================================================================

artifacts_dir = "/Workspace/Users/rajesh.patil@equitable.com/Final_model_files"

print("\n" + "=" * 80)
print("STEP 5: Logging and Registering Model")
print("=" * 80)

# Infer signature
try:
    signature = infer_signature(sample_input, sample_output)
    print(f"✓ Inferred model signature")
except Exception as e:
    print(f"⚠ Could not infer signature: {e}")
    signature = None

# Log model
with mlflow.start_run() as run:
    mlflow.pyfunc.log_model(
        artifact_path="preprocess_and_predict_model",
        python_model=PreprocessAndPredictModel(),
        code_paths=[
            "/Workspace/Users/rajesh.patil@equitable.com/Final_model_files/final_preprocessor.py"
        ],
        artifacts={
            "model_path": "eda_smartlist.models.final_lgbm_multiclass_model",
            "artifacts_path": artifacts_dir
        },
        signature=signature,
        input_example=sample_input if isinstance(sample_input, pd.DataFrame) else None
    )
    run_id = run.info.run_id
    print(f"✓ Logged model with run_id: {run_id}")

# Register the model in Unity Catalog with the specified name
model_uri = f"runs:/{run_id}/preprocess_and_predict_model"
registered_model = mlflow.register_model(
    model_uri=model_uri,
    name=f"{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}"
)

print(f"\n{'=' * 80}")
print("SUCCESS!")
print(f"{'=' * 80}")
print(f"✓ Model registered successfully")
print(f"  Model URI: models:/{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}/{registered_model.version}")
print(f"\nTo use the model:")
print(f"  import mlflow")
print(f"  model = mlflow.pyfunc.load_model('models:/{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}/{registered_model.version}')")
print(f"  predictions = model.predict(input_data)")





================================================================================
STEP 1: Saving/Loading Model Artifacts
================================================================================
✓ Loaded artifacts from /Workspace/Users/rajesh.patil@equitable.com/Final_model_files

================================================================================
STEP 2: Creating Sample Input
================================================================================
✓ Created sample input

================================================================================
STEP 3: Testing Model
================================================================================
✗ Model prediction failed
  Error: 'str' object has no attribute 'predict'
Traceback (most recent call last):
  File "/root/.ipykernel/1571/command-8615534164547256-1986917582", line 140, in <module>
    sample_output = model_instance.predict(None, sample_input)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py", line 77, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/.ipykernel/1571/command-8615534164547255-3359061669", line 341, in predict
    pred_probs = self.model.predict(pred_pd[self.feature_cols])
                 ^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'predict'
