# ============================================================================
# STEP 0: Save Model Artifacts from Training Notebook
# ============================================================================
# Run this cell AFTER training your model in the diagnostics notebook
# This saves all required artifacts to your working directory

import os
import pickle
import lightgbm as lgb

# ============================================================================
# CONFIGURATION - Choose where to save artifacts
# ============================================================================

# Option 1: Save in your working directory (current notebook directory) - RECOMMENDED
WORKING_DIR = os.getcwd()  # Current working directory
ARTIFACTS_PATH = os.path.join(WORKING_DIR, "model_artifacts")

# Option 2: Save in a specific Databricks path (uncomment if preferred)
# ARTIFACTS_PATH = "/dbfs/FileStore/model_artifacts"

# Option 3: Save in Unity Catalog mount point (uncomment if preferred)
# ARTIFACTS_PATH = "/dbfs/mnt/unity-catalog/models/wealth_management_product_recommendation/v1"

print("=" * 80)
print("SAVING MODEL ARTIFACTS")
print("=" * 80)
print(f"Artifacts will be saved to: {ARTIFACTS_PATH}")

# ============================================================================
# STEP 1: Collect Artifacts from Training Notebook
# ============================================================================
# After running your training notebook, you should have these variables:
# Make sure you've run the training cells and have these variables available

# Check if variables exist (they should be from your training notebook)
try:
    # These should be available from your diagnostics notebook after training
    # If running in the same notebook session, they'll be available
    # If running separately, you'll need to load them first
    
    artifacts = {
        'model': "eda_smartlist.models.final_lgbm_multiclass_model",  # Your trained LightGBM model (from Cell 5)
        'prod2id': prod2id,  # Product to ID mapping (from Cell 4)
        'id2prod': id2prod,  # ID to product mapping (from Cell 4)
        'label_map': label_map,  # Label mapping (from Cell 4)
        'num_classes': NUM_CLASSES,  # Number of classes (from Cell 4)
        'feature_cols': model_feature_cols,  # Feature columns list (from Cell 4)
        'max_seq_len': MAX_SEQ_LEN,  # Maximum sequence length (from Cell 4)
        'categorical_mappings': None  # Optional - can be None or a dict
    }
    
    print("\n‚úì Found all required artifacts from training notebook")
    print(f"  - Model: {type(artifacts['model'])}")
    print(f"  - prod2id: {len(artifacts['prod2id'])} products")
    print(f"  - num_classes: {artifacts['num_classes']}")
    print(f"  - feature_cols: {len(artifacts['feature_cols'])} features")
    
except NameError as e:
    print(f"\n‚úó Missing required variable: {e}")
    print("\nPlease ensure you've run the training cells from diagnostics notebook first.")
    print("\nRequired variables from diagnostics notebook:")
    print("  - model: trained LightGBM model (from Cell 5)")
    print("  - prod2id: product to ID mapping dictionary (from Cell 4)")
    print("  - id2prod: ID to product mapping dictionary (from Cell 4)")
    print("  - label_map: label mapping dictionary (from Cell 4)")
    print("  - NUM_CLASSES: number of classes (from Cell 4)")
    print("  - model_feature_cols: list of feature column names (from Cell 4)")
    print("  - MAX_SEQ_LEN: maximum sequence length, usually 10 (from Cell 4)")
    print("\nIf running in a different notebook, you can also manually create artifacts:")
    print("""
    artifacts = {
        'model': your_trained_model,
        'prod2id': your_prod2id_dict,
        'id2prod': your_id2prod_dict,
        'label_map': your_label_map_dict,
        'num_classes': your_num_classes,
        'feature_cols': your_model_feature_cols_list,
        'max_seq_len': 10,
        'categorical_mappings': None  # Optional
    }
    """)
    raise

# ============================================================================
# STEP 2: Save Artifacts
# ============================================================================

# Create directory if it doesn't exist
os.makedirs(ARTIFACTS_PATH, exist_ok=True)
print(f"\n‚úì Created directory: {ARTIFACTS_PATH}")

# Save LightGBM model
model_path = os.path.join(ARTIFACTS_PATH, "model.txt")
artifacts['model'].save_model(model_path)
print(f"‚úì Saved LightGBM model to: {model_path}")

# Save other artifacts (excluding model, which is saved separately)
artifacts_to_save = {
    'prod2id': artifacts['prod2id'],
    'id2prod': artifacts['id2prod'],
    'label_map': artifacts['label_map'],
    'num_classes': artifacts['num_classes'],
    'categorical_mappings': artifacts.get('categorical_mappings'),
    'feature_cols': artifacts['feature_cols'],
    'max_seq_len': artifacts['max_seq_len']
}

artifacts_file = os.path.join(ARTIFACTS_PATH, "artifacts.pkl")
with open(artifacts_file, 'wb') as f:
    pickle.dump(artifacts_to_save, f)
print(f"‚úì Saved artifacts to: {artifacts_file}")

# Display what was saved
print("\n" + "=" * 80)
print("ARTIFACTS SAVED SUCCESSFULLY")
print("=" * 80)
print(f"\nSaved artifacts:")
print(f"  1. model.txt - LightGBM model file")
print(f"  2. artifacts.pkl - Contains:")
for key, value in artifacts_to_save.items():
    if value is not None:
        if isinstance(value, dict):
            print(f"     - {key}: dict with {len(value)} items")
        elif isinstance(value, list):
            print(f"     - {key}: list with {len(value)} items")
        else:
            print(f"     - {key}: {type(value).__name__} = {value}")

print(f"\nüìÅ Artifacts location: {ARTIFACTS_PATH}")
print(f"\n‚úÖ You can now proceed to register the model in the next cell!")
